{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-14T18:29:00.648582Z","iopub.status.busy":"2024-10-14T18:29:00.648049Z","iopub.status.idle":"2024-10-14T18:29:14.453795Z","shell.execute_reply":"2024-10-14T18:29:14.452865Z","shell.execute_reply.started":"2024-10-14T18:29:00.648536Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import gc\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, LeakyReLU, Activation\n","from tensorflow.keras.layers import Concatenate, concatenate, Dropout, BatchNormalization, Flatten\n","from tensorflow.keras.applications import ResNet101\n","from tensorflow.keras.optimizers import Adam\n","from keras.initializers import RandomNormal\n","import numpy as np\n","import random\n","import cv2\n","import matplotlib.pyplot as plt\n","from skimage import color\n","import matplotlib.image as mpimg"]},{"cell_type":"markdown","metadata":{},"source":["## Data"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T18:29:14.456182Z","iopub.status.busy":"2024-10-14T18:29:14.455595Z","iopub.status.idle":"2024-10-14T18:29:14.581923Z","shell.execute_reply":"2024-10-14T18:29:14.581087Z","shell.execute_reply.started":"2024-10-14T18:29:14.456143Z"},"trusted":true},"outputs":[],"source":["class DataGenerator:\n","    def __init__(self):\n","        self.file_paths = [\n","            '/kaggle/input/image-colorization/l/gray_scale.npy',\n","            '/kaggle/input/image-colorization/ab/ab/ab1.npy',\n","            '/kaggle/input/image-colorization/ab/ab/ab2.npy',\n","            '/kaggle/input/image-colorization/ab/ab/ab3.npy'\n","        ]\n","        # Memory-map the file to avoid loading the whole file into RAM\n","        self.channel_memory_map = [np.load(path, mmap_mode='r') for path in self.file_paths]\n","        self.AB_range_map = [self.channel_memory_map[i].shape[0] for i in range(1, 4)]\n","\n","    def _is_valid_image(self, l_channel, ab_channel, ab_variance_threshold=0.005, l_contrast_threshold=0.1):\n","        \"\"\"Check if the image has sufficient color and contrast to be valid for colorization\"\"\"\n","        # Check AB channel color variance (to ensure color is present)\n","        ab_variance = np.var(ab_channel)\n","        if ab_variance < ab_variance_threshold:\n","            return False  # No sufficient color information\n","\n","        # Check L channel contrast (to ensure the image is not washed out)\n","        l_min, l_max = np.min(l_channel), np.max(l_channel)\n","        l_contrast = (l_max - l_min) / 255.0  # Normalize contrast\n","        if l_contrast < l_contrast_threshold:\n","            return False  # Too little contrast\n","\n","        return True  # Image is valid\n","\n","    def _normalize_channels(self, l_channel, ab_channel):\n","        \"\"\"Normalize AB channels to a [0, 1] range.\"\"\"\n","        \n","        # Skip normalization for L channel\n","        l_channel_normalized = l_channel\n","\n","        # Normalize A channel: [42, 226] -> [0, 1]\n","        a_channel_normalized = (ab_channel[:, :, 0] - 42) / 184.0\n","\n","        # Normalize B channel: [20, 223] -> [0, 1]\n","        b_channel_normalized = (ab_channel[:, :, 1] - 20) / 203.0\n","\n","        # Stack the normalized AB channels\n","        ab_channel_normalized = np.stack([a_channel_normalized, b_channel_normalized], axis=-1)\n","\n","        return l_channel_normalized, ab_channel_normalized\n","\n","    def create_batch(self, batch_size):\n","        valid_images = []\n","        while len(valid_images) < batch_size:\n","            # Select random AB array\n","            idx = np.random.randint(0, 3)\n","            \n","            # Select indices\n","            AB_indices = np.random.randint(0, self.AB_range_map[idx], batch_size + int(batch_size * 0.2))\n","            L_difference = sum(self.AB_range_map[:idx])\n","            L_indices = AB_indices + L_difference\n","\n","            # Select batch\n","            l_batch = self.channel_memory_map[0][L_indices]\n","            ab_batch = self.channel_memory_map[idx + 1][AB_indices]\n","\n","            # Filter out low-quality images\n","            for l_img, ab_img in zip(l_batch, ab_batch):\n","                if self._is_valid_image(l_img, ab_img):\n","                    # Normalize the L and AB channels before adding to the batch\n","                    l_normalized, ab_normalized = self._normalize_channels(l_img, ab_img)\n","                    valid_images.append((l_normalized, ab_normalized))\n","                    # valid_images.append((l_img, ab_img))\n","                    if len(valid_images) == batch_size:\n","                        break  # Stop when we have enough valid images\n","\n","        l_batch, ab_batch = zip(*valid_images)\n","        yield np.array(l_batch), np.array(ab_batch)\n","\n","# Instantiate the DataGenerator\n","data_generator = DataGenerator()\n","\n","# Create the generator function to feed data to the model\n","def generator_wrapper(batch_size):\n","    while True:  # Infinite loop to provide batches continuously\n","        l_batch, ab_batch = next(data_generator.create_batch(batch_size))\n","        # Reshape L-channel for the model input (e.g., [batch_size, 256, 256, 1])\n","        l_batch = np.expand_dims(l_batch, axis=-1)\n","        # Yield the batch (input, output) -> L-channel as input, AB-channel as target\n","        yield l_batch, ab_batch"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-14T19:33:35.397820Z","iopub.status.busy":"2024-10-14T19:33:35.397411Z","iopub.status.idle":"2024-10-14T19:33:38.695674Z","shell.execute_reply":"2024-10-14T19:33:38.694707Z","shell.execute_reply.started":"2024-10-14T19:33:35.397782Z"},"trusted":true},"outputs":[],"source":["class GAN:\n","    def __init__(self, input_shape, target_shape):\n","        self.input_shape = input_shape\n","        self.target_shape = target_shape\n","        self.weight_init = RandomNormal(stddev=0.02)\n","        self.generator = self._build_generator()\n","        self.discriminator = self._build_discriminator()\n","        self.model = self._build_gan()\n","        self.patch_shape = self._get_patch_size()\n","        self.batch_size = 32\n","        self.data = generator_wrapper(batch_size=self.batch_size)\n","\n","    def _encoder_block(self, input, filters, kernel, strides):\n","        conv = Conv2D(filters, kernel, strides=strides, padding='same', kernel_initializer=self.weight_init)(input)\n","        conv = BatchNormalization()(conv)\n","        conv = LeakyReLU(alpha=0.2)(conv)\n","        return conv\n","\n","    def _build_generator(self):\n","        in_image = Input(shape=self.input_shape)\n","        in_backbone = Concatenate()([in_image, in_image, in_image])\n","        resnet = ResNet101(\n","            include_top=False,\n","            input_shape=(224, 224, 3),\n","            weights='imagenet'\n","        )\n","        for layer in resnet.layers:\n","            layer.trainable = False\n","        \n","        backbone = resnet(in_backbone)\n","        conv1 = self._encoder_block(in_image, 64, (3, 3), (2, 2))\n","        conv2 = self._encoder_block(conv1, 128, (3, 3), strides=(1, 1))\n","        conv3 = self._encoder_block(conv2, 128, (3, 3), strides=(2, 2))\n","        conv4 = self._encoder_block(conv3, 256, (3, 3), strides=(2, 2))\n","        conv4_ = self._encoder_block(conv4, 256, (3, 3), strides=(1, 1))\n","        conv5 = self._encoder_block(conv4_, 512, (3, 3), strides=(2, 2))\n","        conv5_ = self._encoder_block(conv5, 256, (3, 3), strides=(2, 2))\n","        conc = concatenate([backbone, conv5_])\n","        fusion = self._encoder_block(conc, 512, (1, 1), (1,1))\n","        skip_fusion = concatenate([fusion, conv5_])\n","        \n","        decoder = Conv2DTranspose(1024, (3, 3), strides=(2, 2), padding='same', kernel_initializer=self.weight_init)(skip_fusion)\n","        decoder = Activation('relu')(decoder)\n","        decoder = Dropout(0.25)(decoder)\n","        skip_4_drop = Dropout(0.25)(conv5)\n","        skip_4 = concatenate([decoder, skip_4_drop])\n","        decoder = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer=self.weight_init)(skip_4)\n","        decoder = Activation('relu')(decoder)\n","        decoder = Dropout(0.25)(decoder)\n","        skip_3_drop = Dropout(0.25)(conv4_)\n","        skip_3 = concatenate([decoder, skip_3_drop])\n","        decoder = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=self.weight_init)(skip_3)\n","        decoder = Activation('relu')(decoder)\n","        decoder = Dropout(0.25)(decoder)\n","        decoder = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=self.weight_init)(decoder)\n","        decoder = Activation('relu')(decoder)\n","        decoder = Dropout(0.25)(decoder)\n","        decoder = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same', kernel_initializer=self.weight_init)(decoder)\n","        decoder = Activation('relu')(decoder)\n","        decoder = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', kernel_initializer=self.weight_init)(decoder)\n","        decoder = Activation('relu')(decoder)\n","        output_layer = Conv2D(2, (1, 1), activation='sigmoid')(decoder)\n","        model = Model(in_image, output_layer)\n","        return model\n","\n","    def _build_discriminator(self):\n","        init = RandomNormal(stddev=0.02)\n","        in_src_image = Input(shape=self.input_shape)\n","        in_target_image = Input(shape=self.target_shape)\n","        merged = Concatenate()([in_src_image, in_target_image])\n","\n","        d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n","        d = LeakyReLU(alpha=0.2)(d)\n","        d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","        d = BatchNormalization()(d)\n","        d = LeakyReLU(alpha=0.2)(d)\n","        d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","        d = BatchNormalization()(d)\n","        d = LeakyReLU(alpha=0.2)(d)\n","        d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n","        d = BatchNormalization()(d)\n","        d = LeakyReLU(alpha=0.2)(d)\n","        d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n","        d = BatchNormalization()(d)\n","        d = LeakyReLU(alpha=0.2)(d)\n","        # Patch gan\n","        d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n","        patch_out = Activation('sigmoid')(d)\n","\n","        model = Model([in_src_image, in_target_image], patch_out)\n","        opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","        model.compile(loss='binary_crossentropy', optimizer=opt)\n","        return model\n","\n","    def _build_gan(self):\n","      for layer in self.discriminator.layers:\n","        if not isinstance(layer, BatchNormalization):\n","          layer.trainable = False\n","      in_src = Input(shape=self.input_shape)\n","      gen_out = self.generator(in_src)\n","      dis_out = self.discriminator([in_src, gen_out])\n","      model = Model(in_src, dis_out)\n","      opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","      model.compile(loss='binary_crossentropy', optimizer=opt,metrics=[keras.metrics.BinaryAccuracy()])\n","      return model\n","\n","    def pretrain_generator(self, steps_per_epoch=100, epochs=10):\n","        self.generator.compile(\n","            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.5),  # Adjust learning rate and beta as needed\n","            loss='mean_absolute_error',  # You can also try 'mean_absolute_error'\n","            metrics=['mse', 'mae']  # Monitoring MAE during training\n","        )\n","        self.generator.fit(self.data, steps_per_epoch=steps_per_epoch, epochs=epochs)\n","\n","    def _get_patch_size(self):\n","      return self.discriminator.output.shape[1]\n","\n","    def _generate_real_samples(self):\n","        \"\"\"Generate a batch of real samples from the data generator.\"\"\"\n","        l_batch, ab_batch = next(self.data)  # Get batch from data generator\n","        true_labels = np.ones((self.batch_size, self.patch_shape, self.patch_shape, 1))  # Label as real\n","        return [l_batch, ab_batch], true_labels\n","\n","    def _generate_fake_samples(self, l_batch):\n","        \"\"\"Generate a batch of fake samples (predicted by the generator).\"\"\"\n","        predictions = self.generator.predict(l_batch, verbose=0)  # Predict AB channels\n","        fake_labels = np.zeros((len(l_batch), self.patch_shape, self.patch_shape, 1))  # Label as fake\n","        return predictions, fake_labels\n","\n","    def _denormalize_ab_channel(self, ab_channel_normalized):\n","        \"\"\"Denormalize AB channels back to their original value ranges.\"\"\"    \n","        # Denormalize A channel: [0, 1] -> [42, 226]\n","        a_channel = (ab_channel_normalized[:, :, :, 0] * 184.0) + 42\n","    \n","        # Denormalize B channel: [0, 1] -> [20, 223]\n","        b_channel = (ab_channel_normalized[:, :, :, 1] * 203.0) + 20\n","    \n","        # Stack the denormalized AB channels\n","        ab_channel = np.stack([a_channel, b_channel], axis=-1)\n","    \n","        return ab_channel\n","\n","    def display_results(self, num_images=5):\n","        \"\"\"Display results during training.\"\"\"\n","        l_batch, ab_batch = next(self.data)\n","        predictions = self.generator.predict(l_batch, verbose=0)\n","        # Denormalize AB channels\n","        ab_batch = self._denormalize_ab_channel(ab_batch)\n","        predictions = self._denormalize_ab_channel(predictions)\n","\n","         # Select 5 images to display\n","        real_images = []\n","        generated_images = []\n","        \n","        for i in range(num_images):\n","            # Recombine the L and AB channels for the real images\n","            lab_real = np.stack([l_batch[i, :, :, 0], ab_batch[i, :, :, 0], ab_batch[i, :, :, 1]], axis=-1)\n","            # Recombine the L and AB channels for the generated images\n","            lab_pred = np.stack([l_batch[i, :, :, 0], predictions[i, :, :, 0], predictions[i, :, :, 1]], axis=-1)\n","            # Convert from LAB to RGB for display\n","            rgb_real = cv2.cvtColor(lab_real.astype(np.uint8), cv2.COLOR_LAB2RGB)\n","            rgb_pred = cv2.cvtColor(lab_pred.astype(np.uint8), cv2.COLOR_LAB2RGB)\n","            \n","            real_images.append(rgb_real)\n","            generated_images.append(rgb_pred)\n","        \n","        # Display the images in one row\n","        fig, axes = plt.subplots(2, num_images, figsize=(15, 6))\n","        \n","        for i in range(num_images):\n","            # Display real images\n","            axes[0, i].imshow(real_images[i])\n","            axes[0, i].axis(\"off\")\n","            axes[0, i].set_title(f\"Real {i+1}\")\n","            \n","            # Display generated images\n","            axes[1, i].imshow(generated_images[i])\n","            axes[1, i].axis(\"off\")\n","            axes[1, i].set_title(f\"Generated {i+1}\")\n","    \n","        plt.show()\n","        \n","    def _set_discriminator_trainable(self, trainable=True):\n","        for layer in self.discriminator.layers:\n","            if not isinstance(layer, BatchNormalization):\n","                layer.trainable = trainable\n","\n","    def _train_step(self, L_real, AB_real, y_real, AB_fake, y_fake):\n","        self._set_discriminator_trainable()\n","        with tf.GradientTape() as tape_d:\n","            # Discriminator loss on real samples\n","            d_loss_real = self.discriminator([L_real, AB_real], training=True)\n","            d_loss_real = tf.keras.losses.binary_crossentropy(y_real, d_loss_real)\n","            \n","            # Discriminator loss on fake samples\n","            d_loss_fake = self.discriminator([L_real, AB_fake], training=True)\n","            d_loss_fake = tf.keras.losses.binary_crossentropy(y_fake, d_loss_fake)\n","            \n","            # Total discriminator loss\n","            d_loss = d_loss_real + d_loss_fake\n","\n","        # Compute and apply discriminator gradients\n","        grads_d = tape_d.gradient(d_loss, self.discriminator.trainable_variables)\n","        self.discriminator.optimizer.apply_gradients(zip(grads_d, self.discriminator.trainable_variables))\n","        self._set_discriminator_trainable(False)\n","        with tf.GradientTape() as tape_g:\n","            # Generator loss\n","            g_loss_fake = self.model(L_real, training=True)\n","            g_loss = tf.keras.losses.binary_crossentropy(y_real, g_loss_fake)\n","\n","        # Compute and apply generator gradients\n","        grads_g = tape_g.gradient(g_loss, self.model.trainable_variables)\n","        self.model.optimizer.apply_gradients(zip(grads_g, self.model.trainable_variables))\n","\n","        return d_loss_real, d_loss_fake, g_loss\n","\n","    def train(self, n_epochs=100, batch_size=32):\n","        \"\"\"Train the GAN using the data generator.\"\"\"\n","        self.batch_size = batch_size\n","        self.data = generator_wrapper(batch_size=self.batch_size)\n","        n_steps = 10000  # Adjust for epochs and steps\n","\n","        for i in range(n_steps):\n","            # Generate real samples from the data generator\n","            [L_real, AB_real], y_real = self._generate_real_samples()\n","\n","            # Generate fake samples from the generator\n","            AB_fake, y_fake = self._generate_fake_samples(L_real)\n","\n","            # Perform the training step manually\n","            d_loss_real, d_loss_fake, g_loss = self._train_step(L_real, AB_real, y_real, AB_fake, y_fake)\n","\n","            if i % 250 == 0:\n","                # Discriminator predictions on real and fake samples\n","                d_real_pred = self.discriminator.predict([L_real, AB_real], verbose=0)\n","                d_fake_pred = self.discriminator.predict([L_real, AB_fake], verbose=0)\n","\n","                # Calculate the percentage of true and false predictions\n","                real_acc = np.mean(d_real_pred > 0.5) # real samples classified as real\n","                fake_acc = np.mean(d_fake_pred < 0.5) # fake samples classified as fake\n","                print(f'Real: {real_acc}, Fake: {fake_acc}, G-loss: {np.mean(g_loss)}')\n","                self.display_results()\n","\n","    def save(self):\n","        self.generator.save(f'generator.h5')\n","        \n","inp_shape = (224,224,1)\n","out_shape = (224,224,2)\n","gan = GAN(inp_shape, out_shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Initial generator training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gan.pretrain_generator(steps_per_epoch=500, epochs=10)\n","gan.save()"]},{"cell_type":"markdown","metadata":{},"source":["## GAN Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gan.train(batch_size=24)\n","gan.save()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":50512,"sourceId":125589,"sourceType":"datasetVersion"},{"datasetId":5792676,"sourceId":9515320,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":138411,"modelInstanceId":115148,"sourceId":136086,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
